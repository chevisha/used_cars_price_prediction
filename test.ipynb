{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span\n",
    "from spacy.language import Language\n",
    "import json\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def load_car_data(file_path):\n",
    "    with open(file_path, encoding='utf-8-sig') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    car_data = {}\n",
    "    \n",
    "    for make, models in data.items():\n",
    "        make_data = {}\n",
    "        for model, trims in models.items():\n",
    "            make_data[model] = list(trims.keys())\n",
    "        car_data[make] = make_data\n",
    "    \n",
    "    return car_data\n",
    "\n",
    "# file_path = 'test.json'\n",
    "file_path = r'MakeModelTrimYear.json'\n",
    "#file_path = r'/home/vuk/CarStoryMakeModelTrim.json'\n",
    "car_data = load_car_data(file_path)\n",
    "\n",
    "\n",
    "car_makes = list(car_data.keys())\n",
    "########################\n",
    "\n",
    "car_makes.append(\"mercedes\")    # Mercedes-Benz\n",
    "car_makes.append(\"chevy\")       # Chevrolet\n",
    "car_makes.append(\"vw\")          # Volkswagen\n",
    "car_makes.append(\"rr\")          # Rolls Royce\n",
    "car_makes.append(\"benz\")        # Mercedes-Benz\n",
    "#######################\n",
    "all_models = [model for models in car_data.values() for model in models.keys()]\n",
    "all_trims = [trim for models in car_data.values() for trims in models.values() for trim in trims]\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "@Language.component(\"add_car_entities\")\n",
    "def add_car_entities(doc):\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "\n",
    "    pattern_make = [{\"LOWER\": {\"IN\": [make.lower() for make in car_makes]}}]\n",
    "    matcher.add(\"CAR_MAKE\", [pattern_make])\n",
    "\n",
    "    matches = matcher(doc)\n",
    "    spans = [Span(doc, start, end, label=nlp.vocab.strings[match_id]) for match_id, start, end in matches]\n",
    "    spans = spacy.util.filter_spans(spans)\n",
    "    doc.ents = spans\n",
    "\n",
    "    return doc\n",
    "\n",
    "\n",
    "nlp.add_pipe(\"add_car_entities\", before=\"ner\")\n",
    "\n",
    "#(O(1) time complexity, possibly lesser accuracy)\n",
    "# def get_closest_match(text, options):\n",
    "#     text_set = set(text.lower().split())\n",
    "#     print(text_set)\n",
    "#     max_similarity = 0\n",
    "#     best_match = None\n",
    "\n",
    "#     for option in options:\n",
    "#         print(option)\n",
    "#         option_set = set(option.lower().split())\n",
    "#         similarity = len(text_set & option_set) / len(text_set | option_set)\n",
    "        \n",
    "#         if similarity > max_similarity:\n",
    "#             max_similarity = similarity\n",
    "#             best_match = option\n",
    "#     if max_similarity > 0.01:\n",
    "#         return best_match\n",
    "#     return None\n",
    "    \n",
    "#     #return best_match   \n",
    "\n",
    "\n",
    "def sequence_similarity(option, substring):\n",
    "    option = option.lower()\n",
    "    substring = substring.lower()\n",
    "    \n",
    "    m, n = len(option), len(substring)\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "    \n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if option[i-1] == substring[j-1]:\n",
    "                dp[i][j] = dp[i-1][j-1] + 1\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n",
    "    \n",
    "    return dp[m][n] / max(m, n) \n",
    "\n",
    "\n",
    "def get_closest_match(text, options):\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s#+\\-\\.!]', ' ', text)\n",
    "    \n",
    "    words = text.lower().split()\n",
    "    max_similarity = 0\n",
    "    best_matches = []\n",
    "    all_substrings = []\n",
    "    \n",
    "    for i in range(1, min(4, len(words) + 1)):\n",
    "        for combo in combinations(words, i):\n",
    "            all_substrings.append(' '.join(combo))\n",
    "    \n",
    "    \n",
    "    for substring in all_substrings:\n",
    "        for option in options:\n",
    "            option_lower = option.lower()\n",
    "            option_chars = Counter(option_lower)\n",
    "            substring_chars = Counter(substring)\n",
    "\n",
    "            intersection = sum((option_chars & substring_chars).values())\n",
    "            union = sum((option_chars | substring_chars).values())\n",
    "\n",
    "            similarity = intersection / union if union > 0 else 0\n",
    "\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                best_matches = [(option, substring)]\n",
    "            elif similarity == max_similarity:\n",
    "                best_matches.append((option, substring))\n",
    "\n",
    "    if max_similarity > 0.40:\n",
    "        if len(best_matches) > 1:\n",
    "            best_match = max(best_matches, key=lambda x: (sequence_similarity(x[0], x[1]), len(x[0])))\n",
    "            return best_match[0]\n",
    "        else:\n",
    "            return best_matches[0][0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_info(listing):\n",
    "    doc = nlp(listing)\n",
    "\n",
    "    make = model = trim = year = mileage = None\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"CAR_MAKE\":\n",
    "            make = ent.text\n",
    "            break\n",
    "\n",
    "    if not make:\n",
    "        make = get_closest_match(listing, car_makes)\n",
    "\n",
    "    if not make:\n",
    "        all_models = [model for make_models in car_data.values() for model in make_models]\n",
    "        model = get_closest_match(listing, all_models)\n",
    "        if model:\n",
    "            for m, models in car_data.items():\n",
    "                if model.lower() in [mod.lower() for mod in models]:\n",
    "                    make = m\n",
    "                    break\n",
    "\n",
    "\n",
    "\n",
    "    if make.lower() == \"mercedes\" or make == \"benz\":\n",
    "        make = \"mercedes-benz\"\n",
    "    \n",
    "    if make.lower() == \"vw\":\n",
    "        make = \"volkswagen\"\n",
    "    \n",
    "    if make.lower() == \"rr\":\n",
    "        make = \"rolls-royce\"\n",
    "\n",
    "    if make.lower() == \"chevy\":\n",
    "        make = \"chevrolet\"\n",
    "\n",
    "    if make:\n",
    "        models = list(car_data[make.lower()].keys())\n",
    "        pattern_model = [{\"LOWER\": {\"IN\": [model.lower() for model in models]}}]\n",
    "\n",
    "        matcher = Matcher(nlp.vocab)\n",
    "        matcher.add(\"CAR_MODEL\", [pattern_model])\n",
    "\n",
    "        matches = matcher(doc)\n",
    "        spans = [Span(doc, start, end, label=\"CAR_MODEL\") for match_id, start, end in matches]\n",
    "        spans = spacy.util.filter_spans(spans)\n",
    "        doc.ents = spans\n",
    "        \n",
    "        model = get_closest_match(listing, models)\n",
    "        \n",
    "\n",
    "        if not model:\n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ == \"CAR_MODEL\":\n",
    "                    model = ent.text\n",
    "                    break\n",
    "\n",
    "        if not model:\n",
    "            model_to_model_no_space = {model.replace(\" \", \"\"): model for model in models}\n",
    "            all_models_no_space = list(model_to_model_no_space.keys())\n",
    "            model_no_space = get_closest_match(listing, all_models_no_space)\n",
    "\n",
    "            if model_no_space:\n",
    "                model = model_to_model_no_space[model_no_space]\n",
    "\n",
    "    if not model and make:\n",
    "        all_trims = []\n",
    "        for model_trims in car_data[make.lower()].values():\n",
    "            all_trims.extend(model_trims)\n",
    "        \n",
    "        pattern_trim = [{\"LOWER\": {\"IN\": [trim.lower().replace(\" \", \"\") for trim in all_trims]}}]\n",
    "        \n",
    "        matcher = Matcher(nlp.vocab)\n",
    "        matcher.add(\"CAR_TRIM\", [pattern_trim])\n",
    "        \n",
    "        matches = matcher(doc)\n",
    "        spans = [Span(doc, start, end, label=\"CAR_TRIM\") for match_id, start, end in matches]\n",
    "        spans = spacy.util.filter_spans(spans)\n",
    "        doc.ents = spans\n",
    "        trim = get_closest_match(listing, all_trims)\n",
    "        \n",
    "\n",
    "        if not trim:\n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ == \"CAR_TRIM\":\n",
    "                    trim = ent.text\n",
    "                    break\n",
    "\n",
    "        if not trim:\n",
    "            trim_to_trim_no_space = {trim.replace(\" \", \"\"): trim for trim in all_trims}\n",
    "            all_trims_no_space = list(trim_to_trim_no_space.keys())\n",
    "            trim_no_space = get_closest_match(listing, all_trims_no_space)\n",
    "\n",
    "            if trim_no_space:\n",
    "                trim = trim_to_trim_no_space[trim_no_space]\n",
    "\n",
    "        if trim and trim in all_trims:\n",
    "            for model_name, trims in car_data[make.lower()].items():\n",
    "                if trim.replace(\" \", \"\") in [t.replace(\" \", \"\") for t in trims]:\n",
    "                    model = model_name\n",
    "                    break\n",
    "\n",
    "    elif model:\n",
    "        trims = car_data[make.lower()][model.lower()]\n",
    "        pattern_trim = [{\"LOWER\": {\"IN\": [trim.lower() for trim in trims]}}]\n",
    "\n",
    "        matcher = Matcher(nlp.vocab)\n",
    "        matcher.add(\"CAR_TRIM\", [pattern_trim])\n",
    "\n",
    "        matches = matcher(doc)\n",
    "        spans = [Span(doc, start, end, label=\"CAR_TRIM\") for match_id, start, end in matches]\n",
    "        spans = spacy.util.filter_spans(spans)\n",
    "        doc.ents = spans\n",
    "\n",
    "        trim = get_closest_match(listing, trims)\n",
    "\n",
    "        if not trim:\n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ == \"CAR_TRIM\":\n",
    "                    trim = ent.text\n",
    "                    break\n",
    "\n",
    "        if not trim:\n",
    "            trim_to_trim_no_space = {trim.replace(\" \", \"\"): trim for trim in trims}\n",
    "            all_trims_no_space = list(trim_to_trim_no_space.keys())\n",
    "            trim_no_space = get_closest_match(listing, all_trims_no_space)\n",
    "\n",
    "            if trim_no_space:\n",
    "                trim = trim_to_trim_no_space[trim_no_space]\n",
    "\n",
    "    if not model:\n",
    "        all_models = []\n",
    "        for make_data in car_data.values():\n",
    "            all_models.extend(make_data.keys())\n",
    "\n",
    "        pattern_model = [{\"LOWER\": {\"IN\": [model.lower().replace(\" \", \"\") for model in all_models]}}]\n",
    "        matcher = Matcher(nlp.vocab)\n",
    "        matcher.add(\"CAR_MODEL\", [pattern_model])\n",
    "        matches = matcher(doc)\n",
    "        spans = [Span(doc, start, end, label=\"CAR_MODEL\") for match_id, start, end in matches]\n",
    "        spans = spacy.util.filter_spans(spans)\n",
    "        doc.ents = spans\n",
    "\n",
    "        found_model = get_closest_match(listing, all_models)\n",
    "\n",
    "        if not found_model:\n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ == \"CAR_MODEL\":\n",
    "                    found_model = ent.text\n",
    "                    break\n",
    "\n",
    "        if not found_model:\n",
    "            model_to_model_no_space = {model.replace(\" \", \"\"): model for model in all_models}\n",
    "            all_models_no_space = list(model_to_model_no_space.keys())\n",
    "            model_no_space = get_closest_match(listing, all_models_no_space)\n",
    "\n",
    "            if model_no_space:\n",
    "                found_model = model_to_model_no_space[model_no_space]\n",
    "\n",
    "        if found_model:\n",
    "            model = found_model  # Only set model if it wasn't already set\n",
    "            if not make:\n",
    "                for m, models in car_data.items():\n",
    "                    if model.lower() in [m.lower() for m in models]:\n",
    "                        make = m\n",
    "                        break\n",
    "\n",
    "        if not model:\n",
    "            all_trims = []\n",
    "            for make_data in car_data.values():\n",
    "                for model_data in make_data.values():\n",
    "                    all_trims.extend(model_data)\n",
    "            \n",
    "            pattern_trim = [{\"LOWER\": {\"IN\": [trim.lower().replace(\" \", \"\") for trim in all_trims]}}]\n",
    "            matcher = Matcher(nlp.vocab)\n",
    "            matcher.add(\"CAR_TRIM\", [pattern_trim])\n",
    "            matches = matcher(doc)\n",
    "            spans = [Span(doc, start, end, label=\"CAR_TRIM\") for match_id, start, end in matches]\n",
    "            spans = spacy.util.filter_spans(spans)\n",
    "            doc.ents = spans\n",
    "\n",
    "            found_trim = get_closest_match(listing, all_trims)\n",
    "\n",
    "            if not found_trim:\n",
    "                for ent in doc.ents:\n",
    "                    if ent.label_ == \"CAR_TRIM\":\n",
    "                        found_trim = ent.text\n",
    "                        break\n",
    "\n",
    "            if not found_trim:\n",
    "                trim_to_trim_no_space = {trim.replace(\" \", \"\"): trim for trim in all_trims}\n",
    "                all_trims_no_space = list(trim_to_trim_no_space.keys())\n",
    "                trim_no_space = get_closest_match(listing, all_trims_no_space)\n",
    "\n",
    "                if trim_no_space:\n",
    "                    found_trim = trim_to_trim_no_space[trim_no_space]\n",
    "\n",
    "            if found_trim:\n",
    "                trim = found_trim  # Only set trim if it wasn't already set\n",
    "                # Don't overwrite existing make or model based on trim\n",
    "\n",
    "    if trim and not model:\n",
    "        for make_name, models in car_data.items():\n",
    "            for model_name, trims in models.items():\n",
    "                if trim.lower() in [t.lower() for t in trims]:\n",
    "                    if not model:\n",
    "                        model = model_name\n",
    "                    if not make:\n",
    "                        make = make_name\n",
    "                    break\n",
    "\n",
    "    if model and not make:\n",
    "        for make_name, models in car_data.items():\n",
    "            if model.lower() in [m.lower() for m in models.keys()]:\n",
    "                make = make_name\n",
    "                break\n",
    "            \n",
    "    \n",
    "    if make and model:\n",
    "        if model.lower() not in car_data[make.lower()]:\n",
    "            model = None\n",
    "            trim = None\n",
    "        elif trim:\n",
    "            if trim.lower() not in [t.lower() for t in car_data[make.lower()][model.lower()]]:\n",
    "                trim = None\n",
    "        else:\n",
    "            trims = car_data[make.lower()][model.lower()]\n",
    "            found_trim = get_closest_match(listing, trims)\n",
    "            if found_trim:\n",
    "                trim = found_trim\n",
    "\n",
    "    year_match = re.search(r'\\b(?:19|20)\\d{2}\\b(?!\\s*(?:miles|mi))', listing)\n",
    "    if year_match:\n",
    "        year = int(year_match.group(0))\n",
    "\n",
    "    mileage_pattern = r'\\b(\\d{1,3}(?:,\\d{3})*|\\d+(?:\\.\\d+)?)\\s*(?:miles|mi\\.?|k miles|k mi\\.?|k|km)\\b'\n",
    "    mileage_match = re.search(mileage_pattern, listing, re.IGNORECASE)\n",
    "    if mileage_match:\n",
    "        mileage_str = mileage_match.group(1).replace(',', '')\n",
    "        mileage = int(float(mileage_str) * (1000 if 'k' in mileage_match.group(0).lower() else 1))\n",
    "\n",
    "\n",
    "    \n",
    "    return_dict =  {\n",
    "        'Make': make.lower(),\n",
    "        'Model': model,\n",
    "        'Trim': trim,\n",
    "        'Year': year,\n",
    "        'Mileage': mileage\n",
    "    }\n",
    "\n",
    "    for key, value in return_dict.items():\n",
    "        if value == None:\n",
    "            return_dict[key] = \" \"\n",
    "\n",
    "    return return_dict \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
